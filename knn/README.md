# KNN 算法


## 模型

K Nearest-Neighbor Methods (knn) 称之为最近邻算法，其思想非常简单，就是利用样本中与输出x最相近的k个样本点，对输出 x 进行投票。模型公式：



$$

\hat{Y}(x) = \frac{1}{k} \sum_{ x_i \in N_k(x)} y_i

$$



## 算法

1. 计算输入样本点 x 与样本种每个点之间的距离；

2. 按照距离进行排序;

3. 选择距离最近的前 k 个样本点;

4. 统计这 k 个点中类别的出现频率;

5. 返回类别出现频率最高的类别



## 模型评估

优势: 形式简单，对数据无假定；

劣势: 算法的计算复杂度比较高，当数据量特别大时，遍历样本的开销很大。



## 模型变型

knn的变型方式主要有，对距离计算方法的变化、以及对样本点的加权变化。

1. 距离计算变化

    距离的计算包括：欧氏距离、马氏距离、绝对距离等多种计算距离的方式，选取适当的距离计算公式，可以使knn适用于非数值型数据。

2. 加权变化

    在分类时，可以对样本点进行加权，比如用距离的倒数加权，上文模型中每个样本点权重相同均为$1/k$


## 参考文献

[1] [Machine Learning in Action]()

[2] [The Elements of Statistics Learning]()